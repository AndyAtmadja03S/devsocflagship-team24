// src/server/github/fetchCommits.ts
import { Octokit } from "octokit";
import OpenAI from "openai";
import { isAutoGeneratedCommit, calculateAggregateImpact } from "./helper";

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });
const octokit = new Octokit({ auth: process.env.GITHUB_TOKEN });

export interface CommitFile {
  filename: string;
  patch: string;
}

async function assessPatchesQuality(files: CommitFile[]) {
  try {
    // Filter out very large patches to avoid token limits
    const filteredFiles = files
      .filter(f => f.patch && f.patch.length < 10000)
      .slice(0, 5); // Limit to 5 files max

    if (filteredFiles.length === 0) {
      return { score: null, reasoning: "No suitable patches to assess" };
    }

    const prompt = filteredFiles.map((f, i) => `
File #${i+1}: ${f.filename}
Patch:
${f.patch}
    `).join("\n\n");

    const response = await openai.chat.completions.create({
      model: "gpt-4o-mini",
      messages: [{
        role: "user",
        content: `Analyze the following code patch. 
      You can assume the rest of the file context, but only judge the patch itself.

      Rate the quality of the patch on a scale from 0 to 10 where:
      - 0 = very poor quality
      - 100 = excellent quality

      Consider purpose, readability, efficiency, and maintainability.

      Return ONLY a valid JSON object with the following fields:
      {
        "score": number,       // numeric quality score (0-10)
        "reasoning": string    // short reasoning (1-2 sentences)
      }
      
      "reasoning" should explain the score as completely as possible.

      Code patches:
      ${prompt}`
      }],
      response_format: { type: "json_object" }
    });

    const content = response.choices[0]?.message?.content;
    if (!content) {
      return { score: null, reasoning: "No response from AI" };
    }
    
    return JSON.parse(content);
  } catch (error) {
    console.error("Error assessing patch quality:", error);
    return { score: null, reasoning: "Error assessing quality" };
  }
}

export async function fetchGitHubCommits(repoFullName: string) {
  const [owner, repo] = repoFullName.split("/");
  if (!owner || !repo) {
    throw new Error("Invalid repoFullName. Must be in 'owner/repo' format.");
  }
  
  let commits: any[] = [];
  let page = 1;
  const perPage = 100;

  while (true) {
    // List commits per page
    const response = await octokit.rest.repos.listCommits({
      owner,
      repo,
      per_page: perPage,
      page,
    });

    if (response.data.length === 0) break;

    // Fetch commit details (stats + files) in parallel
    const commitDetails = await Promise.all(
      response.data.map((c) =>
        octokit.rest.repos.getCommit({ owner, repo, ref: c.sha })
      )
    );

    // Map to commits obj including patch
    commits.push(
      ...commitDetails.map((full) => ({
        sha: full.data.sha,
        message: full.data.commit.message,
        date: full.data.commit.author?.date || "",
        author:
          full.data.author?.login || full.data.commit.author?.name || "Unknown",
        avatarUrl: full.data.author?.avatar_url || null,
        additions: full.data.stats?.additions || 0,
        deletions: full.data.stats?.deletions || 0,
        netChanges: (full.data.stats?.additions || 0) - (full.data.stats?.deletions || 0),
        files: full.data.files?.map((f) => ({
          filename: f.filename,
          patch: f.patch || "",
        })),
      }))
    );

    page++;
  }

  // Group commits by author and calculate stats
  const commitsByAuthor = commits.reduce((acc, commit) => {
    if (!acc[commit.author]) {
      acc[commit.author] = {
        commits: [],
        totalCommits: 0,
        linesAdded: 0,
        linesDeleted: 0,
        avatarUrl: commit.avatarUrl
      };
    }
    acc[commit.author].commits.push(commit);
    acc[commit.author].totalCommits += 1;
    acc[commit.author].linesAdded += commit.additions;
    acc[commit.author].linesDeleted += commit.deletions;
    return acc;
  }, {} as Record<string, { commits: typeof commits; totalCommits: number; linesAdded: number; linesDeleted: number;  avatarUrl: string | null }>);

  // Find commit with max net changes for each author and assess quality
  const authorStats = await Promise.all(
    Object.entries(commitsByAuthor).map(async ([author, data]) => {
      // Filter out auto-generated commits
      const meaningfulCommits = data.commits.filter(c => 
        c.files && !isAutoGeneratedCommit(c.files)
      );

      if (meaningfulCommits.length === 0) {
        return {
          author,
          avatarUrl: data.avatarUrl,
          qualityScore: 0,
          reasoning: "No meaningful commits found",
          totalCommits: data.totalCommits,
          linesAdded: data.linesAdded,
          linesDeleted: data.linesDeleted,
        };
      }
      // Calculate aggregate impact score
      const aggregateImpact = calculateAggregateImpact(meaningfulCommits);

      // Find top 3 commits by net changes
      const topCommits = meaningfulCommits
        .sort((a: any, b: any) => Math.abs(b.netChanges) - Math.abs(a.netChanges))
        .slice(0, 3);

      // Assess quality on the largest meaningful commit
      let qualityScore = null;
      let reasoning = "";

      if (topCommits[0]?.files && topCommits[0].files.length > 0) {
        const filesWithPatches = topCommits[0].files.filter((f: any) => f.patch);
        
        if (filesWithPatches.length > 0) {
          const assessment = await assessPatchesQuality(filesWithPatches);
          qualityScore = assessment.score ?? null;
          reasoning = assessment.reasoning ?? "";
        }
      }

      const finalImpactScore = qualityScore !== null
        ? aggregateImpact + qualityScore
        : aggregateImpact;

      return {
        author,
        avatarUrl: data.avatarUrl,
        qualityScore: finalImpactScore,
        reasoning,
        totalCommits: data.totalCommits,
        linesAdded: data.linesAdded,
        linesDeleted: data.linesDeleted,
      };
    })
  );

  return authorStats;
}